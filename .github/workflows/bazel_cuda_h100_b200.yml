name: CI - Bazel H100 and B200 CUDA tests
# This runs if any of the following conditions are met
# H100 and B200 on Workflow dispatch
# H100 and B200 on scheduled every two hours
# H100 and B200 on PR to main that has the 'CI Optional GPU Presubmit' label
on:
  # Runs on PR if label "CI Optional GPU Presubmit" is present.
  workflow_dispatch:
    inputs:
      halt-for-connection:
        description: 'Should this workflow run wait for a remote connection?'
        type: choice
        required: true
        default: 'no'
        options:
        - 'yes'
        - 'no'
      python_version:
        description: 'Hermetic Python version for tests (for example, 3.14).'
        type: string
        required: true
        default: '3.14'
      xla_track:
        description: 'XLA revision used by tests.'
        type: choice
        required: true
        default: 'pinned'
        options:
        - 'pinned'
        - 'head'
  pull_request:
    branches:
      - main
    types: [ labeled, synchronize, opened, reopened ]
  schedule:
    - cron: "0 */2 * * *" # Run once every 2 hours
permissions: {}

# For pull_request events, group by PR number and cancel stale in-progress runs.
# For workflow_dispatch events, group by actor+ref and cancel stale in-progress
# runs from the same actor on the same ref, except on main.
# Never cancel scheduled runs.
concurrency:
  group: >-
    ${{ github.workflow }}-${{
      github.event_name == 'pull_request'
      && format('pr-{0}', github.event.pull_request.number)
      || github.event_name == 'workflow_dispatch'
      && format('dispatch-{0}-{1}', github.actor, github.ref)
      || format('ref-{0}', github.ref)
    }}
  cancel-in-progress: >-
    ${{ github.ref != 'refs/heads/main'
      && (github.event_name == 'pull_request'
      || github.event_name == 'workflow_dispatch') }}

defaults:
  run:
    shell: bash

jobs:
  run_tests:
    if: ${{ github.event.repository.fork == false && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || contains(github.event.pull_request.labels.*.name, 'CI Optional GPU Presubmit')) }}
    runs-on: linux-x86-a4-224-b200-1gpu
    container: 'us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest'
    name: "Bazel single B200 CUDA tests"
# End Presubmit Naming Check github-cuda-presubmits
    steps:
      - uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3  # v6.0.0
        with:
          persist-credentials: false
      - name: Wait For Connection
        uses: google-ml-infra/actions/ci_connection@7f5ca0c263a81ed09ea276524c1b9192f1304e3c
        with:
          halt-dispatch-input: ${{ inputs.halt-for-connection }}
      - name: Run Bazel single B200 CUDA Tests
        env:
          JAXCI_HERMETIC_PYTHON_VERSION: ${{ github.event.inputs.python_version || '3.14' }}
          JAXCI_XLA_TRACK: ${{ github.event.inputs.xla_track || 'pinned' }}
          JAXCI_BAZEL_TARGETS: |
            //tests:cudnn_fusion_test_gpu
            //tests:scaled_matmul_stablehlo_test_gpu
            //tests:fused_attention_stablehlo_test_gpu
            //tests:nn_test_gpu
            //tests/pallas:gpu_tests
            //tests/mosaic:gpu_tests
          JAXCI_TEST_TAG_FILTERS: '-multiaccelerator'
          JAXCI_USE_PARALLEL_ACCELERATOR_RUNNER: '1'
          JAXCI_LOCAL_TEST_JOBS: '8'
          JAXCI_EXCLUDE_TEST_TARGETS: 'PmapTest.testSizeOverflow|.*InterpretTest.*'
          JAXCI_TEST_TIMEOUT: '420'
        run: bash ./ci/run_bazel_cuda_targeted_tests.sh
  run_multiaccelerator_tests:
    if: ${{ github.event.repository.fork == false && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || contains(github.event.pull_request.labels.*.name, 'CI Optional GPU Presubmit')) }}
    runs-on: linux-x86-a3-8g-h100-8gpu
    container: 'us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest'
    name: "Bazel multiple H100 CUDA tests"
    steps:
      - uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3  # v6.0.0
        with:
          persist-credentials: false
      - name: Wait For Connection
        uses: google-ml-infra/actions/ci_connection@7f5ca0c263a81ed09ea276524c1b9192f1304e3c
        with:
          halt-dispatch-input: ${{ inputs.halt-for-connection }}
      - name: Run Bazel multiple H100 CUDA Tests
        env:
          JAXCI_HERMETIC_PYTHON_VERSION: ${{ github.event.inputs.python_version || '3.14' }}
          JAXCI_XLA_TRACK: ${{ github.event.inputs.xla_track || 'pinned' }}
          JAXCI_BAZEL_TARGETS: |
            //tests/mosaic:gpu_tests
            //tests/pallas:gpu_tests
            //tests:array_interoperability_test_gpu
            //tests:cudnn_fusion_test_gpu
            //tests:fused_attention_stablehlo_test_gpu
            //tests:gpu_tests
            //tests:python_callback_test_gpu
            //tests:ragged_collective_test_gpu
            //tests/multiprocess:gpu_tests
            //jax/experimental/jax2tf/tests/multiprocess:gpu_tests
          JAXCI_TEST_TAG_FILTERS: 'multiaccelerator'
          JAXCI_LOCAL_TEST_JOBS: '8'
          JAXCI_EXCLUDE_TEST_TARGETS: 'PmapTest.testSizeOverflow|.*InterpretTest.*'
        run: bash ./ci/run_bazel_cuda_targeted_tests.sh
