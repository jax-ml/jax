# Copyright 2022 The JAX Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import logging
import socket
import time
from jax._src import clusters

logger = logging.getLogger(__name__)

# We use an arbitrarily chosen port for the coordinator since we cannot
# rely on communication to choose one in real time.
coordinator_port = '8476'

metadata_response_code_success = 200

class BaseTpuCluster(clusters.ClusterEnv):

  name: str = "tpu"

  """Abstract cluster supports both single and multislice TPU environments.

  If MEGASCALE_COORDINATOR_ADDRESS is not set, we assume single slice topology.
  Concrete extensions of this class must implement methods for generating a list
    of within-slice workers and a within-slice process ID.
  `get_coordinator_address` must return the address of the host with
  process ID 0 (as returned by `get_process_id`), since the coordinator service
  is started on the host with process ID = 0.
  """

  @classmethod
  def is_env_present(cls) -> bool:
    """Override this method to return True if the environment is present."""
    return False

  @classmethod
  def get_coordinator_address(cls, timeout_secs: int | None) -> str:
    if cls._has_megascale_address():
      # For both GCE via QueuedResources and GKE via JobSet, the
      # Megascale coordinator address is set as the host with process id = 0,
      # so can be used as the jax distributed system coordinator.
      coordinator_address = cls._get_tpu_env_value('MEGASCALE_COORDINATOR_ADDRESS')
    else:
      # For both GCE (QueuedResources and TPUVM create) and GKE via Job API,
      # the workers lists are sorted by process ID so the first one can
      # be used as the jax distributed system coordinator.
      coordinator_address = cls._get_worker_list_in_slice()[0]
    coordinator_address = coordinator_address.split(':')[0]
    logger.debug("TPU Cluster using coordinator address: %s", coordinator_address)
    cls.wait_for_coordinator(coordinator_address, timeout_secs)
    return f'{coordinator_address}:{coordinator_port}'

  @classmethod
  def wait_for_coordinator(cls, coordinator_address, timeout_secs):
    # The coordinator may not be up before the other hosts try to
    # communicate with it. We check for its existence with retries.
    coordinator_found = False
    max_time = time.time() + timeout_secs
    coordinator_retry_secs = 5
    while not coordinator_found and time.time() < max_time:
      try:
        ip_address = socket.gethostbyname(coordinator_address)
        coordinator_found = True
        logger.debug("Found coordinator with address %s", coordinator_address)
      except socket.gaierror:
        logger.debug(
            "Failed to recognize coordinator address %s"
            " retrying...", coordinator_address
        )
        time.sleep(coordinator_retry_secs)
    if not coordinator_found:
      raise RuntimeError(f"Failed to recognize coordinator address {coordinator_address}")

  @classmethod
  def get_process_count(cls) -> int:
    processes_per_slice = len(cls._get_worker_list_in_slice())
    num_slices = cls._get_num_slices()
    total_process_count = processes_per_slice * num_slices
    logger.debug("Total process count of %s = %s processes per slice and %s slices", total_process_count, processes_per_slice, num_slices)
    return total_process_count

  @classmethod
  def get_process_id(cls) -> int:
    process_id_in_slice = cls._get_process_id_in_slice()
    slice_id = cls._get_slice_id()
    processes_per_slice = len(cls._get_worker_list_in_slice())
    process_id = process_id_in_slice + slice_id * processes_per_slice
    logger.debug("Process ID of %s generated by within-slice id %s and slice id %s", process_id, process_id_in_slice, slice_id)
    return process_id

  @classmethod
  def _get_num_slices(cls) -> int:
    if cls._has_megascale_address():
      return int(cls._get_tpu_env_value('MEGASCALE_NUM_SLICES'))
    else:
      return 1

  @classmethod
  def _get_slice_id(cls) -> int:
    if cls._has_megascale_address():
      return int(cls._get_tpu_env_value('MEGASCALE_SLICE_ID'))
    else:
      return 0

  @classmethod
  def _has_megascale_address(cls):
    return cls._get_tpu_env_value('MEGASCALE_COORDINATOR_ADDRESS') is not None

  @staticmethod
  def _get_process_id_in_slice() -> int:
    """Returns a process ID that is unique within slice."""
    raise NotImplementedError()

  @staticmethod
  def _get_worker_list_in_slice() -> list[str]:
    """Returns a list of worker endpoints/hostnames within slice."""
    raise NotImplementedError()

  @staticmethod
  def _get_tpu_env_value(key):
    """Returns the value of a TPU environment variable."""
    raise NotImplementedError()

